# üöÄ WebSocket Chat with Ollama - Modular Architecture

A production-ready, modular chat application with dual RAG (Retrieval-Augmented Generation) systems, real-time WebSocket communication, and multiple LLM support.

## ‚ú® Key Features

- üèóÔ∏è **Modular Architecture**: Scalable sub-app design with clear separation of concerns
- üîÑ **Dual RAG Systems**: Compare Manual vs LangChain implementations side-by-side
- üß† **ChromaDB Support**: Persistent vector store option alongside FAISS
- ü§ñ **AI Agents**: ReAct agent with function calling, tool use, and reasoning (NEW!)
- ü§ñ **Multiple AI Models**: Gemma 2B, Phi-3, Llama 3.2, Qwen 2.5
- üìÅ **Document Upload**: PDF, DOCX, TXT, Markdown support
- üîå **Single Port**: All endpoints accessible through one port (8081)
- üê≥ **Fully Dockerized**: Complete containerized setup with Docker Compose
- ‚ö° **Real-time Communication**: WebSocket-based chat for instant messaging
- üìä **OpenAPI Documentation**: Auto-generated API docs at `/docs`
- üé® **Modern UI**: Clean, responsive chat interface with system toggle

## üèóÔ∏è Architecture

### Modular Structure
```
app.py (Main Server/Orchestrator)
‚îú‚îÄ‚îÄ common/          ‚Üí Shared APIs (health, models, system switching)
‚îú‚îÄ‚îÄ app_manual/      ‚Üí Manual RAG implementation
‚îú‚îÄ‚îÄ app_langchain/   ‚Üí LangChain RAG implementation
‚îú‚îÄ‚îÄ app_agents/      ‚Üí AI Agent system with ReAct pattern (NEW!)
‚îî‚îÄ‚îÄ static/          ‚Üí Frontend (HTML/JS/CSS)
```

### Benefits
- ‚úÖ **Scalable**: Easy to add new modules (ChromaDB, LlamaIndex, etc.)
- ‚úÖ **Testable**: Each module can be tested independently
- ‚úÖ **Maintainable**: Clear code organization and separation
- ‚úÖ **Discoverable**: All endpoints auto-documented
- ‚úÖ **Backward Compatible**: Legacy endpoints preserved

## üì¶ Project Structure

```
websockets/
‚îú‚îÄ‚îÄ app.py                           # Main orchestrator server
‚îú‚îÄ‚îÄ app_old_backup.py                # Backup of previous monolithic version
‚îú‚îÄ‚îÄ requirements.txt                 # Python dependencies
‚îú‚îÄ‚îÄ task                             # Task/project notes
‚îú‚îÄ‚îÄ MODULAR_QUICK_REF.md            # Quick reference guide
‚îÇ
‚îú‚îÄ‚îÄ common/                          # Shared APIs module
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ app.py                       # Health, models, system switching
‚îÇ
‚îú‚îÄ‚îÄ app_manual/                      # Manual RAG module
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ app.py                       # Manual RAG router
‚îÇ   ‚îî‚îÄ‚îÄ rag_store.py                 # Custom RAG implementation
‚îÇ
‚îú‚îÄ‚îÄ app_langchain/                   # LangChain RAG module
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ app.py                       # LangChain RAG router
‚îÇ   ‚îî‚îÄ‚îÄ langchain_rag.py             # LangChain implementation
‚îÇapp_agents/                      # AI Agent module (NEW!)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ app.py                       # Agent API router
‚îÇ   ‚îú‚îÄ‚îÄ agent1.py                    # ReAct agent implementation
‚îÇ   ‚îî‚îÄ‚îÄ tools.py                     # Tool definitions (calculator, time, weather, etc.)
‚îÇ
‚îú‚îÄ‚îÄ 
‚îú‚îÄ‚îÄ builds/                          # Docker configuration
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                   # FastAPI container
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml           # Multi-container orchestration
‚îÇ   ‚îú‚îÄ‚îÄ pull-model.sh               # Script to pull Ollama models
‚îÇ   ‚îú‚îÄ‚îÄ pull-all-models.sh          # Pull all supported models
‚îÇ   ‚îî‚îÄ‚îÄ verify.sh                   # Verify setup
‚îÇ
‚îú‚îÄ‚îÄ data/                            # Data directory (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ rag_store.json              # Manual RAG storage
‚îÇ   ‚îú‚îÄ‚îÄ AGENT1_GUIDE.md             # AI Agent learning guide (NEW!)
‚îÇ   ‚îú‚îÄ‚îÄ MODULAR_ARCHITECTURE.md     # Architecture deep dive
‚îÇ   ‚îú‚îÄ‚îÄ CHAT_FLOW.md                # Communication flow
‚îÇ   ‚îú‚îÄ‚îÄ DUAL_SYSTEM_GUIDE.md        # Dual RAG comparison
‚îÇ   ‚îú‚îÄ‚îÄ MODEL_SELECTION.md          # Model information
‚îÇ   ‚îú‚îÄ‚îÄ QUICK_REFERENCE.md          # Quick commands
‚îÇ   ‚îú‚îÄ‚îÄ PROJECT_SUMMARY.md          # Project summary
‚îÇ   ‚îú‚îÄ‚îÄ future_scope.md             # Future enhancements
‚îÇ   ‚îî‚îÄ‚îÄ understand_rag_without_code.md  # RAG explanation
‚îÇ
‚îî‚îÄ‚îÄ static/                          # Frontend assets
    ‚îú‚îÄ‚îÄ index.html                  # Chat interface
    ‚îú‚îÄ‚îÄ agent1.html                 # Agent1 demo UI (NEW!)
‚îÇ   ‚îú‚îÄ‚îÄ PROJECT_SUMMARY.md          # Project summary
‚îÇ   ‚îú‚îÄ‚îÄ future_scope.md             # Future enhancements
‚îÇ   ‚îî‚îÄ‚îÄ understand_rag_without_code.md  # RAG explanation
‚îÇ
‚îî‚îÄ‚îÄ static/                          # Frontend assets
    ‚îú‚îÄ‚îÄ index.html                  # Chat interface
    ‚îú‚îÄ‚îÄ script.js                   # WebSocket client
    ‚îú‚îÄ‚îÄ style.css                   # Styling
    ‚îî‚îÄ‚îÄ test.html                   # Test page
```

## üöÄ Quick Start

### Prerequisites
- Docker and Docker Compose
- 4GB+ free RAM
- Internet connection for initial setup

### 1. Navigate to project
```bash
cd /Users/shivam/Desktop/workspace/poc/websockets
```

### 2. Start services
```bash
cd builds/
docker compose up -d
```

### 3. Wait for models to load
```bash
# Check logs
docker compose logs -f

# Verify models loaded
docker exec ollama ollama list
```

### 4. Access application
- **Frontend**: http://localhost:8081
- **Agent1 UI**: http://localhost:8081/agents/agent1 (NEW!)
- **API Docs**: http://localhost:8081/docs
- **Health Check**: http://localhost:8081/health

### Enable ChromaDB (Optional)
```bash
# in project root
echo 'RAG_VECTORSTORE=chroma' >> .env
echo 'RAG_VECTORSTORE_PATH=/app/data/chroma_db' >> .env
cd builds && docker compose up -d --build
```

## üì° API Endpoints (19 Total)

### Common Endpoints
```
GET  /health                     - Health check
GET  /api/models                 - List available models
POST /api/models/load            - Load specific model
POST /api/system/switch          - Switch between systems
GET  /api/system/current         - Get current system
```

### Manual RAG Module
```
GET  /api/rag/manual/stats       - Manual RAG stats
POST /api/rag/manual/ingest_text - Ingest text
POST /api/rag/manual/ingest_file - Ingest file
POST /api/rag/manual/preview     - Preview context
```

### LangChain RAG Module
```
GET  /api/rag/langchain/stats    - LangChain stats
POST /api/rag/langchain/ingest_text - Ingest text
POST /api/rag/langchain/ingest_file - Ingest file
POST /api/rag/langchain/query    - Direct query
```

Chroma vs FAISS (LangChain):
- Set `RAG_VECTORSTORE=faiss|chroma` (env overrides YAML config)
- For Chroma, set `RAG_VECTORSTORE_PATH=/app/data/chroma_db` (mapped to `data/` on host)

### Unified Endpoints
```
GET  /                           - Main HTML page
GET  /agents/agent1              - Agent1 demo UI (NEW!)
WS   /ws                         - WebSocket chat
GET  /api/rag/stats              - Aggregated stats
POST /api/rag/ingest_file        - Upload to both systems
POST /api/rag/ingest_text        - Ingest to both systems
POST /api/rag/preview            - Preview context
```

### Agent Endpoints (NEW!)
```
GET  /api/agents/agent1/info     - Agent metadata & capabilities
GET  /api/agents/agent1/tools    - List available tools
POST /api/agents/agent1/query    - Query agent with message
POST /api/agents/agent1/reset    - Reset conversation history
```

## üß™ Testing

### List all endpoints
```bash
curl -s http://localhost:8081/openapi.json | \
  python3 -c "import sys, json; \
  data = json.load(sys.stdin); \
  print('\\n'.join([f'{method.upper()} {path}' \
  for path, methods in data['paths'].items() \
  for method in methods.keys()]))"
```

### Test health
```bash
curl http://localhost:8081/health | python3 -m json.tool
```

### Test stats
```bash
# Unified stats (both systems)
curl http://localhost:8081/api/rag/stats | python3 -m json.tool

# Manual system only
curl http://localhost:8081/api/rag/manual/stats | python3 -m json.tool

# LangChain system only
curl http://localhost:8081/api/rag/langchain/stats | python3 -m json.tool
```

## ‚öôÔ∏è Configuration

- Config files live in [config/langchain.yaml](config/langchain.yaml) and [config/manual.yaml](config/manual.yaml).
- At runtime, settings are loaded from YAML and merged with environment variables via [common/config.py](common/config.py).
- Precedence: environment variables override YAML, which override code defaults.
- To make YAML configs available inside the FastAPI container, add this volume to the `fastapi` service in [builds/docker-compose.yml](builds/docker-compose.yml):
    - `../config:/app/config`

Key settings (LangChain):
- `vectorstore`: `faiss` or `chroma` (default `faiss`)
- `vectorstore_path`: persistent path for Chroma (e.g., `/app/data/chroma_db`)
- `chunk_size`, `chunk_overlap`: text chunking for embeddings
- `rag_enabled`, `rag_top_k`, `save_uploads`, `upload_dir`

Switching vector stores:
- Set `RAG_VECTORSTORE=faiss|chroma` in `.env` (env takes priority over YAML).
- For Chroma, also set `RAG_VECTORSTORE_PATH=/app/data/chroma_db`.

### ChromaDB Test Suite
Run the comprehensive test (auto-detects port, defaults to 8081):
```bash
python tests/test_chroma.py
```
Flags:
- `--base-url http://localhost:8081` to override target
- `--timeout 60` to extend request timeout
- `--skip-persistence` to skip the manual restart step

## üîß Development

### Rebuild after changes
```bash
cd builds/
docker compose build fastapi
docker compose up -d
```

### View logs
```bash
cd builds/
docker compose logs -f fastapi      # Follow logs
docker compose logs --tail=50       # Last 50 lines
```

### Stop services
```bash
cd builds/
docker compose down
```

## üìö Documentation

| Document | Description |
|----------|-------------|
| [MODULAR_ARCHITECTURE.md](docs/architecture/MODULAR_ARCHITECTURE.md) | Deep dive into modular design |
| [MODULAR_QUICK_REF.md](MODULAR_QUICK_REF.md) | Quick reference card |
| [SETUP.md](docs/setup/SETUP.md) | Detailed setup instructions |
| [CHAT_FLOW.md](docs/flows/CHAT_FLOW.md) | WebSocket communication flow |
| [DUAL_SYSTEM_GUIDE.md](docs/guides/DUAL_SYSTEM_GUIDE.md) | Manual vs LangChain comparison |
| [MODEL_SELECTION.md](docs/reference/MODEL_SELECTION.md) | Model information and selection |
| [future_scope.md](docs/roadmap/future_scope.md) | Planned features and enhancements |

## üéØ Adding a New Module

Example: Adding ChromaDB support

1. **Create module directory:**
```bash
mkdir app_chromadb
touch app_chromadb/__init__.py
touch app_chromadb/app.py
```

2. **Create router:**
```python
# app_chromadb/app.py
from fastapi import APIRouter

router = APIRouter(prefix="/api/rag/chromadb", tags=["chroma-rag"])

@router.get("/stats")
async def chromadb_stats():
    return {"system": "chromadb", "status": "active"}
```

3. **Register in main app:**
```python
# app.py
from app_chromadb.app import router as chromadb_router
app.include_router(chromadb_router)
```

4. **Update Dockerfile:**
```dockerfile
COPY ../app_chromadb/ ./app_chromadb/
```

5. **Rebuild:**
```bash
cd builds/
docker compose build fastapi && docker compose up -d
```

6. **Test:**
```bash
curl http://localhost:8081/api/rag/chromadb/stats
```

**New endpoint automatically available at `/docs`!**

## üî¨ Technology Stack

- **Backend**: FastAPI 0.109.0, Uvicorn
- **AI**: Ollama (Gemma 2B, Phi-3, Llama 3.2, Qwen 2.5)
- **Embeddings**: nomic-embed-text
- **RAG (Manual)**: NumPy, custom cosine similarity
- **RAG (LangChain)**: LangChain, FAISS/Chroma, RecursiveCharacterTextSplitter
- **File Parsing**: pypdf (PDF), python-docx (DOCX)
- **Containerization**: Docker, Docker Compose
- **Frontend**: Vanilla JavaScript, WebSocket API

## üìä Current Status

- ‚úÖ Modular architecture implemented
- ‚úÖ 19 endpoints registered
- ‚úÖ All modules operational
- ‚úÖ Both RAG systems working
- ‚úÖ WebSocket communication active
- ‚úÖ OpenAPI documentation available
- ‚úÖ Production ready

## üöÄ Future Enhancements

See [future_scope.md](docs/future_scope.md) for detailed roadmap:

1. **AI Agents** - Function calling, tool integration
2. **Memory System** - Conversation history, session management
3. **Advanced RAG** - Hybrid search, reranking, citations
4. **Streaming** - Server-sent events for token streaming
5. **Multi-Agent** - Coordinated agent systems

## ü§ù Contributing

This is a POC project. To extend:

1. Create a new module directory
2. Implement router with endpoints
3. Register in main `app.py`
4. Update Dockerfile
5. Rebuild and test

## üìÑ License

This is a proof-of-concept project for learning purposes.

## üôè Acknowledgments

- Ollama for local LLM inference
- LangChain for RAG framework
- FastAPI for modern Python web framework
- All open-source contributors

---

**Version**: 2.0.0 - Modular Architecture  
**Status**: ‚úÖ Production Ready  
**Port**: 8081 (single port for all services)  
**Architecture**: Modular with Sub-Apps  
**Date**: January 2026
