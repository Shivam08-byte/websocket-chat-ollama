# ğŸš€ WebSocket Chat with Ollama - Modular Architecture

A production-ready, modular chat application with dual RAG (Retrieval-Augmented Generation) systems, real-time WebSocket communication, and multiple LLM support.

## âœ¨ Key Features

- ğŸ—ï¸ **Modular Architecture**: Scalable sub-app design with clear separation of concerns
- ğŸ”„ **Dual RAG Systems**: Compare Manual vs LangChain implementations side-by-side
- ğŸ¤– **Multiple AI Models**: Gemma 2B, Phi-3, Llama 3.2, Qwen 2.5
- ğŸ“ **Document Upload**: PDF, DOCX, TXT, Markdown support
- ğŸ”Œ **Single Port**: All 19 endpoints accessible through one port (8081)
- ğŸ³ **Fully Dockerized**: Complete containerized setup with Docker Compose
- âš¡ **Real-time Communication**: WebSocket-based chat for instant messaging
- ğŸ“Š **OpenAPI Documentation**: Auto-generated API docs at `/docs`
- ğŸ¨ **Modern UI**: Clean, responsive chat interface with system toggle

## ğŸ—ï¸ Architecture

### Modular Structure
```
app.py (Main Server/Orchestrator)
â”œâ”€â”€ common/          â†’ Shared APIs (health, models, system switching)
â”œâ”€â”€ app_manual/      â†’ Manual RAG implementation
â”œâ”€â”€ app_langchain/   â†’ LangChain RAG implementation
â””â”€â”€ static/          â†’ Frontend (HTML/JS/CSS)
```

### Benefits
- âœ… **Scalable**: Easy to add new modules (ChromaDB, LlamaIndex, etc.)
- âœ… **Testable**: Each module can be tested independently
- âœ… **Maintainable**: Clear code organization and separation
- âœ… **Discoverable**: All endpoints auto-documented
- âœ… **Backward Compatible**: Legacy endpoints preserved

## ğŸ“¦ Project Structure

```
websockets/
â”œâ”€â”€ app.py                           # Main orchestrator server
â”œâ”€â”€ app_old_backup.py                # Backup of previous monolithic version
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ task                             # Task/project notes
â”œâ”€â”€ MODULAR_QUICK_REF.md            # Quick reference guide
â”‚
â”œâ”€â”€ common/                          # Shared APIs module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ app.py                       # Health, models, system switching
â”‚
â”œâ”€â”€ app_manual/                      # Manual RAG module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                       # Manual RAG router
â”‚   â””â”€â”€ rag_store.py                 # Custom RAG implementation
â”‚
â”œâ”€â”€ app_langchain/                   # LangChain RAG module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                       # LangChain RAG router
â”‚   â””â”€â”€ langchain_rag.py             # LangChain implementation
â”‚
â”œâ”€â”€ builds/                          # Docker configuration
â”‚   â”œâ”€â”€ Dockerfile                   # FastAPI container
â”‚   â”œâ”€â”€ docker-compose.yml           # Multi-container orchestration
â”‚   â”œâ”€â”€ pull-model.sh               # Script to pull Ollama models
â”‚   â”œâ”€â”€ pull-all-models.sh          # Pull all supported models
â”‚   â””â”€â”€ verify.sh                   # Verify setup
â”‚
â”œâ”€â”€ data/                            # Data directory (gitignored)
â”‚   â”œâ”€â”€ rag_store.json              # Manual RAG storage
â”‚   â”œâ”€â”€ uploads/                    # Uploaded files
â”‚   â””â”€â”€ vectorstore/                # LangChain FAISS vectors
â”‚
â”œâ”€â”€ docs/                            # Documentation
â”‚   â”œâ”€â”€ README.md                   # Project overview
â”‚   â”œâ”€â”€ SETUP.md                    # Detailed setup guide
â”‚   â”œâ”€â”€ MODULAR_ARCHITECTURE.md     # Architecture deep dive
â”‚   â”œâ”€â”€ CHAT_FLOW.md                # Communication flow
â”‚   â”œâ”€â”€ DUAL_SYSTEM_GUIDE.md        # Dual RAG comparison
â”‚   â”œâ”€â”€ MODEL_SELECTION.md          # Model information
â”‚   â”œâ”€â”€ QUICK_REFERENCE.md          # Quick commands
â”‚   â”œâ”€â”€ PROJECT_SUMMARY.md          # Project summary
â”‚   â”œâ”€â”€ future_scope.md             # Future enhancements
â”‚   â””â”€â”€ understand_rag_without_code.md  # RAG explanation
â”‚
â””â”€â”€ static/                          # Frontend assets
    â”œâ”€â”€ index.html                  # Chat interface
    â”œâ”€â”€ script.js                   # WebSocket client
    â”œâ”€â”€ style.css                   # Styling
    â””â”€â”€ test.html                   # Test page
```

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose
- 4GB+ free RAM
- Internet connection for initial setup

### 1. Navigate to project
```bash
cd /Users/shivam/Desktop/workspace/poc/websockets
```

### 2. Start services
```bash
cd builds/
docker compose up -d
```

### 3. Wait for models to load
```bash
# Check logs
docker compose logs -f

# Verify models loaded
docker exec ollama ollama list
```

### 4. Access application
- **Frontend**: http://localhost:8081
- **API Docs**: http://localhost:8081/docs
- **Health Check**: http://localhost:8081/health

## ğŸ“¡ API Endpoints (19 Total)

### Common Endpoints
```
GET  /health                     - Health check
GET  /api/models                 - List available models
POST /api/models/load            - Load specific model
POST /api/system/switch          - Switch between systems
GET  /api/system/current         - Get current system
```

### Manual RAG Module
```
GET  /api/rag/manual/stats       - Manual RAG stats
POST /api/rag/manual/ingest_text - Ingest text
POST /api/rag/manual/ingest_file - Ingest file
POST /api/rag/manual/preview     - Preview context
```

### LangChain RAG Module
```
GET  /api/rag/langchain/stats    - LangChain stats
POST /api/rag/langchain/ingest_text - Ingest text
POST /api/rag/langchain/ingest_file - Ingest file
POST /api/rag/langchain/query    - Direct query
```

### Unified Endpoints
```
GET  /                           - Main HTML page
WS   /ws                         - WebSocket chat
GET  /api/rag/stats              - Aggregated stats
POST /api/rag/ingest_file        - Upload to both systems
POST /api/rag/ingest_text        - Ingest to both systems
POST /api/rag/preview            - Preview context
```

## ğŸ§ª Testing

### List all endpoints
```bash
curl -s http://localhost:8081/openapi.json | \
  python3 -c "import sys, json; \
  data = json.load(sys.stdin); \
  print('\\n'.join([f'{method.upper()} {path}' \
  for path, methods in data['paths'].items() \
  for method in methods.keys()]))"
```

### Test health
```bash
curl http://localhost:8081/health | python3 -m json.tool
```

### Test stats
```bash
# Unified stats (both systems)
curl http://localhost:8081/api/rag/stats | python3 -m json.tool

# Manual system only
curl http://localhost:8081/api/rag/manual/stats | python3 -m json.tool

# LangChain system only
curl http://localhost:8081/api/rag/langchain/stats | python3 -m json.tool
```

## ğŸ”§ Development

### Rebuild after changes
```bash
cd builds/
docker compose build fastapi
docker compose up -d
```

### View logs
```bash
cd builds/
docker compose logs -f fastapi      # Follow logs
docker compose logs --tail=50       # Last 50 lines
```

### Stop services
```bash
cd builds/
docker compose down
```

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [MODULAR_ARCHITECTURE.md](docs/MODULAR_ARCHITECTURE.md) | Deep dive into modular design |
| [MODULAR_QUICK_REF.md](MODULAR_QUICK_REF.md) | Quick reference card |
| [SETUP.md](docs/SETUP.md) | Detailed setup instructions |
| [CHAT_FLOW.md](docs/CHAT_FLOW.md) | WebSocket communication flow |
| [DUAL_SYSTEM_GUIDE.md](docs/DUAL_SYSTEM_GUIDE.md) | Manual vs LangChain comparison |
| [MODEL_SELECTION.md](docs/MODEL_SELECTION.md) | Model information and selection |
| [future_scope.md](docs/future_scope.md) | Planned features and enhancements |

## ğŸ¯ Adding a New Module

Example: Adding ChromaDB support

1. **Create module directory:**
```bash
mkdir app_chromadb
touch app_chromadb/__init__.py
touch app_chromadb/app.py
```

2. **Create router:**
```python
# app_chromadb/app.py
from fastapi import APIRouter

router = APIRouter(prefix="/api/rag/chromadb", tags=["chroma-rag"])

@router.get("/stats")
async def chromadb_stats():
    return {"system": "chromadb", "status": "active"}
```

3. **Register in main app:**
```python
# app.py
from app_chromadb.app import router as chromadb_router
app.include_router(chromadb_router)
```

4. **Update Dockerfile:**
```dockerfile
COPY ../app_chromadb/ ./app_chromadb/
```

5. **Rebuild:**
```bash
cd builds/
docker compose build fastapi && docker compose up -d
```

6. **Test:**
```bash
curl http://localhost:8081/api/rag/chromadb/stats
```

**New endpoint automatically available at `/docs`!**

## ğŸ”¬ Technology Stack

- **Backend**: FastAPI 0.109.0, Uvicorn
- **AI**: Ollama (Gemma 2B, Phi-3, Llama 3.2, Qwen 2.5)
- **Embeddings**: nomic-embed-text
- **RAG (Manual)**: NumPy, custom cosine similarity
- **RAG (LangChain)**: LangChain, FAISS, RecursiveCharacterTextSplitter
- **File Parsing**: pypdf (PDF), python-docx (DOCX)
- **Containerization**: Docker, Docker Compose
- **Frontend**: Vanilla JavaScript, WebSocket API

## ğŸ“Š Current Status

- âœ… Modular architecture implemented
- âœ… 19 endpoints registered
- âœ… All modules operational
- âœ… Both RAG systems working
- âœ… WebSocket communication active
- âœ… OpenAPI documentation available
- âœ… Production ready

## ğŸš€ Future Enhancements

See [future_scope.md](docs/future_scope.md) for detailed roadmap:

1. **AI Agents** - Function calling, tool integration
2. **Memory System** - Conversation history, session management
3. **Advanced RAG** - Hybrid search, reranking, citations
4. **Streaming** - Server-sent events for token streaming
5. **Multi-Agent** - Coordinated agent systems

## ğŸ¤ Contributing

This is a POC project. To extend:

1. Create a new module directory
2. Implement router with endpoints
3. Register in main `app.py`
4. Update Dockerfile
5. Rebuild and test

## ğŸ“„ License

This is a proof-of-concept project for learning purposes.

## ğŸ™ Acknowledgments

- Ollama for local LLM inference
- LangChain for RAG framework
- FastAPI for modern Python web framework
- All open-source contributors

---

**Version**: 2.0.0 - Modular Architecture  
**Status**: âœ… Production Ready  
**Port**: 8081 (single port for all services)  
**Architecture**: Modular with Sub-Apps  
**Date**: January 2026
